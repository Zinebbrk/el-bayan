import os
import pandas as pd

# Define base dataset directory
base_dir = "dataset"

# Directory structure
folders = [
    "sentences/correct",
    "sentences/incorrect",
    "sentences/raw_text",
    "annotations",
    "rules",
    "difficulty",
    "feedback",
    "exercises",
    "learners",
    "audio/sentence_audio",
    "audio/word_audio",
    "meta",
    "evaluation"
]

# CSV file templates with column names
csv_templates = {
    # Sentences
    "sentences/correct/sentences_correct.csv": [
        "sentence_id", "sentence", "sentence_diacritized", "translation", "rule_id", "difficulty", "source", "i3rab", "syntactic_structure_ref"
    ],
    "sentences/incorrect/sentences_incorrect.csv": [
        "sentence_id", "wrong_sentence", "correct_sentence", "error_type", "error_subtype", "error_span_start", "error_span_end", "severity", "rule_id", "difficulty", "learner_level_hint"
    ],

    # Annotations
    "annotations/tokens.csv": [
        "sentence_id", "token_id", "token", "lemma", "pos"
    ],
    "annotations/morphological_features.csv": [
        "sentence_id", "token_id", "case", "gender", "number", "tense", "mood", "voice", "aspect", "person", "voice_diacritic", "orthographic_variant"
    ],
    "annotations/dependencies.csv": [
        "sentence_id", "token_id", "head_token_id", "dep_label"
    ],
    "annotations/diacritization.csv": [
        "sentence_id", "token_id", "undiacritized", "diacritized", "confidence"
    ],
    "annotations/i3rab.csv": [
        "sentence_id", "token_id", "case_mark", "syntactic_role", "governor_token_id"
    ],

    # Rules
    "grammar_rules.csv": [
        "rule_id", "rule_name", "description", "example", "pedagogical_goal", "prerequisites", "common_misconceptions"
    ],
    "rules/rule_to_sentence.csv": [
        "rule_id", "sentence_id"
    ],
    "rules/rule_taxonomy.csv": [
        "rule_id", "parent_rule_id", "category", "subcategory", "notes"
    ],
    "rules/conjugation_patterns.csv": [
        "verb_lemma", "form", "tense", "person", "number", "gender", "mood", "diacritized_form", "features_json"
    ],

    # Difficulty
    "difficulty/rule_difficulty.csv": [
        "rule_id", "level", "category", "evidence_metric", "last_updated", "source"
    ],
    "difficulty/sentence_difficulty.csv": [
        "sentence_id", "level", "category", "evidence_metric", "last_updated", "source"
    ],

    # Feedback
    "feedback/correction_suggestions.csv": [
        "error_id", "sentence_id", "wrong_sentence", "correct_sentence", "suggestion", "rule_id"
    ],
    "feedback/explanation_text.csv": [
        "error_id", "rule_id", "explanation_ar", "explanation_en", "reading_level", "example_ids"
    ],
    "feedback/adaptive_next_step.csv": [
        "error_id", "next_exercise_type", "recommended_topic", "repeat_times"
    ],
    "feedback/error_templates.csv": [
        "error_type", "subtype", "template_text_ar", "template_text_en", "rule_id"
    ],
    "feedback/rubrics.csv": [
        "rubric_id", "dimension", "levels_json"
    ],
    "feedback/safety_checks.csv": [
        "check_id", "category", "status", "notes"
    ],

    # Exercises (with shared metadata columns)
    "exercises/fill_in_blank.csv": [
        "exercise_id", "sentence_id", "question", "answer", "level", "time_limit_sec", "points", "hint_refs", "audio_ref"
    ],
    "exercises/error_correction.csv": [
        "exercise_id", "sentence_id", "incorrect_sentence", "correct_sentence", "level", "time_limit_sec", "points", "hint_refs", "audio_ref"
    ],
    "exercises/mcq_grammar.csv": [
        "exercise_id", "sentence_id", "question", "option_a", "option_b", "option_c", "option_d", "correct_option", "level", "time_limit_sec", "points", "hint_refs", "audio_ref"
    ],
    "exercises/conjugation_drill.csv": [
        "exercise_id", "verb_lemma", "prompt_features_json", "correct_form", "distractors", "rule_id", "level", "time_limit_sec", "points", "hint_refs", "audio_ref"
    ],
    "exercises/i3rab_analysis.csv": [
        "exercise_id", "sentence_id", "target_tokens", "correct_labels", "distractors", "explanation_ref", "level", "time_limit_sec", "points", "hint_refs", "audio_ref"
    ],
    "exercises/generative_prompt.csv": [
        "exercise_id", "prompt_ar", "expected_traits", "rubric_ref", "level", "time_limit_sec", "points", "hint_refs", "audio_ref"
    ],

    # Learners
    "learners/learner_profiles.csv": [
        "learner_id", "name", "current_level", "goals", "preferred_script", "access_constraints"
    ],
    "learners/learner_progress.csv": [
        "learner_id", "sentence_id", "is_correct", "attempts", "timestamp"
    ],
    "learners/learner_errors_history.csv": [
        "learner_id", "error_id", "repeat_count"
    ],
    "learners/interactions.csv": [
        "learner_id", "session_id", "timestamp", "sentence_id", "action_type", "response", "latency_ms", "device_type", "offline_flag"
    ],
    "learners/adaptive_state.csv": [
        "learner_id", "estimated_level", "mastery_by_rule_json", "last_recommendation", "next_due_ts"
    ],

    # Audio
    "audio/alignments.csv": [
        "sentence_id", "token_id", "start_ms", "end_ms", "speaker_id"
    ],

    # Meta
    "meta/sources.csv": [
        "source_id", "type", "url_or_ref", "license"
    ],
    "meta/splits.csv": [
        "sentence_id", "split", "rationale"
    ],
    "meta/models.csv": [
        "model_id", "base_model", "version", "finetune_data_ref", "prompt_template_ref"
    ],
    "meta/prompts.csv": [
        "prompt_id", "template_text", "variables_json", "purpose"
    ],

    # Evaluation
    "evaluation/metrics.csv": [
        "metric_id", "name", "definition"
    ],
    "evaluation/results.csv": [
        "model_id", "eval_set", "metric_id", "value", "notes"
    ],
    "evaluation/human_ratings.csv": [
        "item_id", "rater_id", "clarity", "correctness", "usefulness", "comments"
    ]
}

# Step 1: Create folders
for folder in folders:
    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)

# Step 2: Create CSV files with headers
for file_path, columns in csv_templates.items():
    full_path = os.path.join(base_dir, file_path)
    df = pd.DataFrame(columns=columns)
    df.to_csv(full_path, index=False)

print("âœ… Dataset structure created successfully!")
